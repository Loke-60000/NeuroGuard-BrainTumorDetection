{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "from src.load_data import *\n",
    "from src.img_processing import *\n",
    "from src.convert import *\n",
    "from src.img_processing import process_folder_for_cropping, check_folder_cropping_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train\"\n",
    "test_path = \"data/test\"\n",
    "val_path = \"data/val\"\n",
    "images, labels = load_data(test_path)\n",
    "\n",
    "print(\"Nombre total d'images chargées :\", len(images))\n",
    "# print(\"Nombre total de labels chargés :\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(test_path)\n",
    "plt.imshow(images[12])\n",
    "plt.title(f\"label : {labels[12]}\")\n",
    "\n",
    "print(\"Nombre total d'images chargées :\", len(images))\n",
    "# print(\"Nombre total de labels chargés :\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 256\n",
    "width = 256\n",
    "\n",
    "yes_folder_path = 'brain_tumor_dataset/yes/'\n",
    "yes_output_folder = 'img_cropped/yes/'\n",
    "process_folder_for_cropping(yes_folder_path, yes_output_folder, width, height)\n",
    "\n",
    "no_folder_path = 'brain_tumor_dataset/no/'\n",
    "no_output_folder = 'img_cropped/no/'\n",
    "process_folder_for_cropping(no_folder_path, no_output_folder, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path_clean = process_folder_for_cropping()\n",
    "train_path_clean = process_folder_for_cropping()\n",
    "val_path_clean = process_folder_for_cropping()\n",
    "# plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propre_yes = check_folder_cropping_quality(yes_output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propre_no = check_folder_cropping_quality(no_output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(propre_yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données de test\n",
    "test_images, test_labels = load_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Créer un modèle VGG-16 pré-entraîné (ne pas inclure la couche dense finale)\n",
    "# base_model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# NUM_CLASSES = 1\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(base_model)\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "\n",
    "# # Figer les poids du VGG\n",
    "# model.layers[0].trainable = False\n",
    "\n",
    "# # Compiler le modèle\n",
    "# model.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer=RMSprop(lr=1e-4),\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # Afficher la structure du modèle\n",
    "# model.summary()\n",
    "\n",
    "# # Créer un générateur d'images pour la data augmentation\n",
    "# datagen = ImageDataGenerator(\n",
    "#     rotation_range=15,\n",
    "#     width_shift_range=0.05,\n",
    "#     height_shift_range=0.05,\n",
    "#     rescale=1./255,\n",
    "#     shear_range=0.05,\n",
    "#     brightness_range=[0.1, 1.5],\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True\n",
    "# )\n",
    "\n",
    "# # Ajuster le générateur aux données d'entraînement\n",
    "# datagen.fit(images)\n",
    "\n",
    "# # Entraîner le modèle avec l'augmentation de données\n",
    "# model.fit(datagen.flow(images, labels, batch_size=32),\n",
    "#           epochs=10,\n",
    "#           steps_per_epoch=len(images) // 32,\n",
    "#           validation_data=(test_images, test_labels))\n",
    "\n",
    "# # Évaluer le modèle sur les données de test\n",
    "# test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "# print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
